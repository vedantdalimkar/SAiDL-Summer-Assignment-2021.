{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-15T06:21:33.411954Z",
     "iopub.status.busy": "2021-08-15T06:21:33.411365Z",
     "iopub.status.idle": "2021-08-15T06:21:39.368496Z",
     "shell.execute_reply": "2021-08-15T06:21:39.367604Z",
     "shell.execute_reply.started": "2021-08-15T06:21:33.411860Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-15T06:21:39.370101Z",
     "iopub.status.busy": "2021-08-15T06:21:39.369812Z",
     "iopub.status.idle": "2021-08-15T06:21:39.769713Z",
     "shell.execute_reply": "2021-08-15T06:21:39.768720Z",
     "shell.execute_reply.started": "2021-08-15T06:21:39.370072Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tr</td>\n",
       "      <td>0</td>\n",
       "      <td>But it was not here .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tr</td>\n",
       "      <td>0</td>\n",
       "      <td>The one no one cared about .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tr</td>\n",
       "      <td>0</td>\n",
       "      <td>The Bible would be staying here .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tr</td>\n",
       "      <td>0</td>\n",
       "      <td>It 's a long hike . \"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tr</td>\n",
       "      <td>0</td>\n",
       "      <td>A very bad idea .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104563</th>\n",
       "      <td>te</td>\n",
       "      <td>5</td>\n",
       "      <td>The Shadow Stone cannot bring people back fro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104564</th>\n",
       "      <td>te</td>\n",
       "      <td>5</td>\n",
       "      <td>His shadow that until this very moment had alw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104565</th>\n",
       "      <td>te</td>\n",
       "      <td>5</td>\n",
       "      <td>They each seemed frozen on the spot , their we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104566</th>\n",
       "      <td>te</td>\n",
       "      <td>5</td>\n",
       "      <td>The Red Army and the Sack Swords , both formid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104567</th>\n",
       "      <td>te</td>\n",
       "      <td>5</td>\n",
       "      <td>He looked down upon them the way a lion would ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>104568 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0  1                                                  2\n",
       "0       tr  0                              But it was not here .\n",
       "1       tr  0                       The one no one cared about .\n",
       "2       tr  0                  The Bible would be staying here .\n",
       "3       tr  0                              It 's a long hike . \"\n",
       "4       tr  0                                  A very bad idea .\n",
       "...     .. ..                                                ...\n",
       "104563  te  5   The Shadow Stone cannot bring people back fro...\n",
       "104564  te  5  His shadow that until this very moment had alw...\n",
       "104565  te  5  They each seemed frozen on the spot , their we...\n",
       "104566  te  5  The Red Army and the Sack Swords , both formid...\n",
       "104567  te  5  He looked down upon them the way a lion would ...\n",
       "\n",
       "[104568 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../input/sentlen/sentence_length.txt', sep = \"\\t\", header = None)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-15T06:21:39.771660Z",
     "iopub.status.busy": "2021-08-15T06:21:39.771380Z",
     "iopub.status.idle": "2021-08-15T06:21:39.800804Z",
     "shell.execute_reply": "2021-08-15T06:21:39.799804Z",
     "shell.execute_reply.started": "2021-08-15T06:21:39.771633Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5301</th>\n",
       "      <td>tr</td>\n",
       "      <td>0</td>\n",
       "      <td>Hang it !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59035</th>\n",
       "      <td>tr</td>\n",
       "      <td>4</td>\n",
       "      <td>Taylor knew that they had almost reached the f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4621</th>\n",
       "      <td>tr</td>\n",
       "      <td>0</td>\n",
       "      <td>Tell us another one .\\ntr\\t0\\tHow were you sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25546</th>\n",
       "      <td>tr</td>\n",
       "      <td>1</td>\n",
       "      <td>But the prospect now confronting his congealed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98182</th>\n",
       "      <td>te</td>\n",
       "      <td>1</td>\n",
       "      <td>Then the wagon came out with a loud pop .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33747</th>\n",
       "      <td>tr</td>\n",
       "      <td>2</td>\n",
       "      <td>Lord Brogan quelled a sudden rush of anger at ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51748</th>\n",
       "      <td>tr</td>\n",
       "      <td>3</td>\n",
       "      <td>' They 're trying to kill you and Lucas , ' he...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32677</th>\n",
       "      <td>tr</td>\n",
       "      <td>2</td>\n",
       "      <td>She could hear his laugh following her all the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45778</th>\n",
       "      <td>tr</td>\n",
       "      <td>3</td>\n",
       "      <td>Dusk turned into night we kept a lookout expec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22103</th>\n",
       "      <td>tr</td>\n",
       "      <td>1</td>\n",
       "      <td>The time machine , you dork !</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>104568 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0  1                                                  2\n",
       "5301   tr  0                                         Hang it ! \n",
       "59035  tr  4  Taylor knew that they had almost reached the f...\n",
       "4621   tr  0   Tell us another one .\\ntr\\t0\\tHow were you sa...\n",
       "25546  tr  1  But the prospect now confronting his congealed...\n",
       "98182  te  1          Then the wagon came out with a loud pop .\n",
       "...    .. ..                                                ...\n",
       "33747  tr  2  Lord Brogan quelled a sudden rush of anger at ...\n",
       "51748  tr  3  ' They 're trying to kill you and Lucas , ' he...\n",
       "32677  tr  2  She could hear his laugh following her all the...\n",
       "45778  tr  3  Dusk turned into night we kept a lookout expec...\n",
       "22103  tr  1                     The time machine , you dork ! \n",
       "\n",
       "[104568 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#shuffling the dataset\n",
    "df = df.sample(104568)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-15T06:21:39.803445Z",
     "iopub.status.busy": "2021-08-15T06:21:39.803035Z",
     "iopub.status.idle": "2021-08-15T06:21:39.812396Z",
     "shell.execute_reply": "2021-08-15T06:21:39.811146Z",
     "shell.execute_reply.started": "2021-08-15T06:21:39.803401Z"
    }
   },
   "outputs": [],
   "source": [
    "#using a subset of the entire data, using the entire data resulted in excess memory allocation\n",
    "#splitting the data into train,validation and test set\n",
    "task_train = df[2][:60000].to_numpy()\n",
    "task_val = df[2][60000:61000].to_numpy()\n",
    "task_test = df[2][61000:66000].to_numpy()\n",
    "\n",
    "task_train_labels = df[1][:60000].to_numpy()\n",
    "task_val_labels = df[1][60000:61000].to_numpy()\n",
    "task_test_labels = df[1][61000:66000].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-15T06:21:39.814499Z",
     "iopub.status.busy": "2021-08-15T06:21:39.814077Z",
     "iopub.status.idle": "2021-08-15T06:21:39.825823Z",
     "shell.execute_reply": "2021-08-15T06:21:39.824773Z",
     "shell.execute_reply.started": "2021-08-15T06:21:39.814461Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(' Hang it ! ', 0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_train[0],task_train_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-15T06:21:39.827507Z",
     "iopub.status.busy": "2021-08-15T06:21:39.827180Z",
     "iopub.status.idle": "2021-08-15T06:21:39.836387Z",
     "shell.execute_reply": "2021-08-15T06:21:39.835516Z",
     "shell.execute_reply.started": "2021-08-15T06:21:39.827476Z"
    }
   },
   "outputs": [],
   "source": [
    "task_train = task_train.reshape(-1,1)\n",
    "task_val = task_val.reshape(-1,1)\n",
    "task_test = task_test.reshape(-1,1)\n",
    "\n",
    "\n",
    "task_train_labels = task_train_labels.reshape(-1,1)\n",
    "task_val_labels = task_val_labels.reshape(-1,1)\n",
    "task_test_labels = task_test_labels.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-15T06:21:39.837683Z",
     "iopub.status.busy": "2021-08-15T06:21:39.837423Z",
     "iopub.status.idle": "2021-08-15T06:21:39.849555Z",
     "shell.execute_reply": "2021-08-15T06:21:39.848566Z",
     "shell.execute_reply.started": "2021-08-15T06:21:39.837658Z"
    }
   },
   "outputs": [],
   "source": [
    "x_concat = np.vstack((task_train,task_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-15T06:21:39.851621Z",
     "iopub.status.busy": "2021-08-15T06:21:39.851192Z",
     "iopub.status.idle": "2021-08-15T06:21:59.356401Z",
     "shell.execute_reply": "2021-08-15T06:21:59.355535Z",
     "shell.execute_reply.started": "2021-08-15T06:21:39.851577Z"
    }
   },
   "outputs": [],
   "source": [
    "#Transforming a batch of strings (one sample = one string) into a list of token indices using TextVectorization layer.\n",
    "#Applying text vectoriztion to the entire text dataset, then feeding it to a model that expects integer sequences as inputs.\n",
    "\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "\n",
    "vectorizer = TextVectorization(max_tokens=30000, output_sequence_length=20)\n",
    "\n",
    "#calling the vectorization layer's adapt() method on the dataset. When this layer is adapted, it analyzes the dataset, determine the frequency of individual string values, and creates a 'vocabulary' from them.\n",
    "vectorizer.adapt(x_concat)\n",
    "\n",
    "\n",
    "task_train = task_train.reshape(-1)\n",
    "task_val = task_val.reshape(-1)\n",
    "task_test = task_test.reshape(-1)\n",
    "\n",
    "\n",
    "#vectorizing the dataset\n",
    "task_train_1 = vectorizer(np.array([[s] for s in task_train])).numpy()\n",
    "task_val_1 = vectorizer(np.array([[s] for s in task_val])).numpy()\n",
    "task_test_1 = vectorizer(np.array([[s] for s in task_test])).numpy()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-15T06:21:59.360276Z",
     "iopub.status.busy": "2021-08-15T06:21:59.359813Z",
     "iopub.status.idle": "2021-08-15T06:21:59.446782Z",
     "shell.execute_reply": "2021-08-15T06:21:59.445930Z",
     "shell.execute_reply.started": "2021-08-15T06:21:59.360234Z"
    }
   },
   "outputs": [],
   "source": [
    "#creating a dict mapping words to their indices:\n",
    "voc = vectorizer.get_vocabulary()\n",
    "word_index = dict(zip(voc, range(len(voc))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-15T06:21:59.449263Z",
     "iopub.status.busy": "2021-08-15T06:21:59.448833Z",
     "iopub.status.idle": "2021-08-15T06:22:13.288155Z",
     "shell.execute_reply": "2021-08-15T06:22:13.287255Z",
     "shell.execute_reply.started": "2021-08-15T06:21:59.449220Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "#loading pre-trained word embeddings\n",
    "path_to_glove_file = '../input/sentlen/glove.6B.100d.txt'\n",
    "\n",
    "embeddings_index = {}\n",
    "with open(path_to_glove_file,encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        word, coefs = line.split(maxsplit=1)\n",
    "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
    "        embeddings_index[word] = coefs\n",
    "\n",
    "print(\"Found %s word vectors.\" % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-15T06:22:13.289486Z",
     "iopub.status.busy": "2021-08-15T06:22:13.289223Z",
     "iopub.status.idle": "2021-08-15T06:22:13.370025Z",
     "shell.execute_reply": "2021-08-15T06:22:13.368926Z",
     "shell.execute_reply.started": "2021-08-15T06:22:13.289459Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 26227 words (534 misses)\n"
     ]
    }
   ],
   "source": [
    "#Preparing a corresponding embedding matrix that we can use in a Keras Embedding layer.\n",
    "#The embedding matrix is a NumPy matrix where entry at index i is the pre-trained vector for the word of index i in our vectorizer's vocabulary.num_tokens = len(voc) + 2\n",
    "embedding_dim = 100\n",
    "hits = 0\n",
    "misses = 0\n",
    "\n",
    "# Prepare embedding matrix\n",
    "embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # Words not found in embedding index will be all-zeros.\n",
    "        # This includes the representation for \"padding\" and \"OOV\"\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        hits += 1\n",
    "    else:\n",
    "        misses += 1\n",
    "print(\"Converted %d words (%d misses)\" % (hits, misses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-15T06:22:13.371440Z",
     "iopub.status.busy": "2021-08-15T06:22:13.371171Z",
     "iopub.status.idle": "2021-08-15T06:22:13.379382Z",
     "shell.execute_reply": "2021-08-15T06:22:13.378343Z",
     "shell.execute_reply.started": "2021-08-15T06:22:13.371413Z"
    }
   },
   "outputs": [],
   "source": [
    "#Loading the pre-trained word embeddings matrix into an Embedding layer.\n",
    "from tensorflow.keras.layers import Embedding\n",
    "\n",
    "embedding_layer = Embedding(\n",
    "    num_tokens,\n",
    "    embedding_dim,\n",
    "    embeddings_initializer=keras.initializers.Constant(embedding_matrix),\n",
    "    trainable=False, name = \"embed_layer\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-15T06:22:13.381295Z",
     "iopub.status.busy": "2021-08-15T06:22:13.380898Z",
     "iopub.status.idle": "2021-08-15T06:22:13.450010Z",
     "shell.execute_reply": "2021-08-15T06:22:13.449279Z",
     "shell.execute_reply.started": "2021-08-15T06:22:13.381264Z"
    }
   },
   "outputs": [],
   "source": [
    "#using Keras callbacks function to save the model with the best validation set accuracy\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "filepath=\"model.{epoch:03d}-{val_accuracy:.3f}.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor = 'val_accuracy', save_best_only = True, mode = 'max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-15T06:22:13.451485Z",
     "iopub.status.busy": "2021-08-15T06:22:13.451046Z",
     "iopub.status.idle": "2021-08-15T06:22:13.459713Z",
     "shell.execute_reply": "2021-08-15T06:22:13.458319Z",
     "shell.execute_reply.started": "2021-08-15T06:22:13.451456Z"
    }
   },
   "outputs": [],
   "source": [
    "#loading the model used for the NLI task and building another model over it to test whether the length of the sentence is encoded in the representation output by the NLI model\n",
    "def get_model():\n",
    "        model = tf.keras.models.load_model('../input/sentlen/NLI_model.030-0.793.h5')\n",
    "        layer_name = \"encoder_layer\"\n",
    "        probe_intermediate_layer = tf.keras.Model(inputs=model.get_layer('input_layer').input, outputs=model.get_layer(layer_name).output)\n",
    "        probe_intermediate_layer.trainable = False\n",
    "        probe_input = tf.keras.layers.Input(shape=(None,), dtype=\"int64\")\n",
    "\n",
    "        p = probe_intermediate_layer(probe_input)\n",
    "        p = tf.keras.layers.Dense(300, activation = 'relu')(p)\n",
    "        p = tf.keras.layers.Dropout(0.3)(p)\n",
    "        p = tf.keras.layers.Dense(300, activation = 'relu')(p)\n",
    "        p = tf.keras.layers.Dropout(0.3)(p)\n",
    "        outputs = tf.keras.layers.Dense(6, activation = 'softmax')(p)\n",
    "\n",
    "        probe_model = tf.keras.Model(inputs = probe_input, outputs = outputs)\n",
    "        return probe_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-15T06:22:13.461628Z",
     "iopub.status.busy": "2021-08-15T06:22:13.461318Z",
     "iopub.status.idle": "2021-08-15T06:22:24.733393Z",
     "shell.execute_reply": "2021-08-15T06:22:24.732474Z",
     "shell.execute_reply.started": "2021-08-15T06:22:13.461598Z"
    }
   },
   "outputs": [],
   "source": [
    "# detect and init the TPU\n",
    "tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n",
    "\n",
    "# instantiate a distribution strategy\n",
    "tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "\n",
    "# instantiating the model in the strategy scope creates the model on the TPU\n",
    "with tpu_strategy.scope():\n",
    "        probe_model = get_model()\n",
    "        probe_model.compile(optimizer='rmsprop',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-15T06:22:24.734825Z",
     "iopub.status.busy": "2021-08-15T06:22:24.734548Z",
     "iopub.status.idle": "2021-08-15T06:22:24.743743Z",
     "shell.execute_reply": "2021-08-15T06:22:24.741232Z",
     "shell.execute_reply.started": "2021-08-15T06:22:24.734798Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, None)]            0         \n",
      "_________________________________________________________________\n",
      "model (Functional)           (None, 300)               2376550   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 300)               90300     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 300)               90300     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 1806      \n",
      "=================================================================\n",
      "Total params: 2,558,956\n",
      "Trainable params: 182,406\n",
      "Non-trainable params: 2,376,550\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "probe_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-15T06:22:24.745409Z",
     "iopub.status.busy": "2021-08-15T06:22:24.745114Z",
     "iopub.status.idle": "2021-08-15T06:22:28.026318Z",
     "shell.execute_reply": "2021-08-15T06:22:28.025155Z",
     "shell.execute_reply.started": "2021-08-15T06:22:24.745381Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_layer (InputLayer)        [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embed_layer (Embedding)         (None, None, 100)    2000200     input_layer[0][0]                \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_layer (Dense)             (None, None, 150)    15150       embed_layer[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 150)    15150       embed_layer[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, None, 150)    0           dense_layer[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, None, 150)    0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "encoder_layer (Bidirectional)   (None, 300)          361200      dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   (None, 300)          361200      dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 600)          0           encoder_layer[0][0]              \n",
      "                                                                 bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 600)          360600      concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 600)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 600)          360600      dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 600)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 600)          360600      dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 600)          0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 3)            1803        dropout_4[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 3,836,503\n",
      "Trainable params: 1,836,303\n",
      "Non-trainable params: 2,000,200\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#summary of the pre-trained model (this model was used for the primary task)\n",
    "model = tf.keras.models.load_model('../input/sentlen/NLI_model.030-0.793.h5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-15T06:22:28.027836Z",
     "iopub.status.busy": "2021-08-15T06:22:28.027556Z",
     "iopub.status.idle": "2021-08-15T06:22:28.032448Z",
     "shell.execute_reply": "2021-08-15T06:22:28.031362Z",
     "shell.execute_reply.started": "2021-08-15T06:22:28.027808Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "filepath=\"probe_model.{epoch:03d}-{val_accuracy:.3f}.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor = 'val_accuracy', save_best_only = True, mode = 'max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-15T06:22:28.033939Z",
     "iopub.status.busy": "2021-08-15T06:22:28.033654Z",
     "iopub.status.idle": "2021-08-15T06:24:03.340663Z",
     "shell.execute_reply": "2021-08-15T06:24:03.339599Z",
     "shell.execute_reply.started": "2021-08-15T06:22:28.033912Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "59/59 [==============================] - 11s 77ms/step - loss: 1.2845 - accuracy: 0.4514 - val_loss: 0.8861 - val_accuracy: 0.6170\n",
      "Epoch 2/20\n",
      "59/59 [==============================] - 1s 22ms/step - loss: 0.9417 - accuracy: 0.5918 - val_loss: 0.8417 - val_accuracy: 0.6200\n",
      "Epoch 3/20\n",
      "59/59 [==============================] - 1s 20ms/step - loss: 0.8943 - accuracy: 0.6097 - val_loss: 0.8045 - val_accuracy: 0.6380\n",
      "Epoch 4/20\n",
      "59/59 [==============================] - 1s 22ms/step - loss: 0.8651 - accuracy: 0.6208 - val_loss: 0.7972 - val_accuracy: 0.6420\n",
      "Epoch 5/20\n",
      "59/59 [==============================] - 1s 21ms/step - loss: 0.8464 - accuracy: 0.6256 - val_loss: 0.7647 - val_accuracy: 0.6440\n",
      "Epoch 6/20\n",
      "59/59 [==============================] - 1s 20ms/step - loss: 0.8332 - accuracy: 0.6342 - val_loss: 0.7595 - val_accuracy: 0.6470\n",
      "Epoch 7/20\n",
      "59/59 [==============================] - 1s 22ms/step - loss: 0.8152 - accuracy: 0.6401 - val_loss: 0.7553 - val_accuracy: 0.6500\n",
      "Epoch 8/20\n",
      "59/59 [==============================] - 1s 21ms/step - loss: 0.8125 - accuracy: 0.6398 - val_loss: 0.7431 - val_accuracy: 0.6550\n",
      "Epoch 9/20\n",
      "59/59 [==============================] - 1s 20ms/step - loss: 0.7966 - accuracy: 0.6485 - val_loss: 0.7557 - val_accuracy: 0.6450\n",
      "Epoch 10/20\n",
      "59/59 [==============================] - 1s 21ms/step - loss: 0.7924 - accuracy: 0.6532 - val_loss: 0.7390 - val_accuracy: 0.6730\n",
      "Epoch 11/20\n",
      "59/59 [==============================] - 1s 20ms/step - loss: 0.7828 - accuracy: 0.6514 - val_loss: 0.7465 - val_accuracy: 0.6540\n",
      "Epoch 12/20\n",
      "59/59 [==============================] - 1s 20ms/step - loss: 0.7761 - accuracy: 0.6566 - val_loss: 0.7462 - val_accuracy: 0.6500\n",
      "Epoch 13/20\n",
      "59/59 [==============================] - 1s 21ms/step - loss: 0.7710 - accuracy: 0.6558 - val_loss: 0.7237 - val_accuracy: 0.6560\n",
      "Epoch 14/20\n",
      "59/59 [==============================] - 1s 21ms/step - loss: 0.7706 - accuracy: 0.6581 - val_loss: 0.7271 - val_accuracy: 0.6600\n",
      "Epoch 15/20\n",
      "59/59 [==============================] - 1s 21ms/step - loss: 0.7621 - accuracy: 0.6610 - val_loss: 0.7197 - val_accuracy: 0.6530\n",
      "Epoch 16/20\n",
      "59/59 [==============================] - 1s 20ms/step - loss: 0.7623 - accuracy: 0.6603 - val_loss: 0.7253 - val_accuracy: 0.6570\n",
      "Epoch 17/20\n",
      "59/59 [==============================] - 1s 22ms/step - loss: 0.7457 - accuracy: 0.6672 - val_loss: 0.7070 - val_accuracy: 0.6590\n",
      "Epoch 18/20\n",
      "59/59 [==============================] - 1s 21ms/step - loss: 0.7533 - accuracy: 0.6657 - val_loss: 0.7109 - val_accuracy: 0.6620\n",
      "Epoch 19/20\n",
      "59/59 [==============================] - 1s 22ms/step - loss: 0.7503 - accuracy: 0.6667 - val_loss: 0.7208 - val_accuracy: 0.6410\n",
      "Epoch 20/20\n",
      "59/59 [==============================] - 1s 22ms/step - loss: 0.7375 - accuracy: 0.6682 - val_loss: 0.7100 - val_accuracy: 0.6640\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fed4615bad0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probe_model.fit(task_train_1,task_train_labels,validation_data = (task_val_1,task_val_labels), epochs = 20, batch_size = 1024, callbacks = [checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-15T06:24:03.342678Z",
     "iopub.status.busy": "2021-08-15T06:24:03.342242Z",
     "iopub.status.idle": "2021-08-15T06:24:03.350308Z",
     "shell.execute_reply": "2021-08-15T06:24:03.349009Z",
     "shell.execute_reply.started": "2021-08-15T06:24:03.342632Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 164,   84,  161,   47,   18,   73,   95,   41,   13, 1391,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0]),\n",
       " array([0]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_train_1[2],task_train_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-15T06:24:03.352502Z",
     "iopub.status.busy": "2021-08-15T06:24:03.352074Z",
     "iopub.status.idle": "2021-08-15T06:24:07.125491Z",
     "shell.execute_reply": "2021-08-15T06:24:07.124379Z",
     "shell.execute_reply.started": "2021-08-15T06:24:03.352460Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 4s 17ms/step - loss: 0.7222 - accuracy: 0.6744\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7221677899360657, 0.6743999719619751]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probe_model.evaluate(task_test_1,task_test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-15T06:24:07.127129Z",
     "iopub.status.busy": "2021-08-15T06:24:07.126794Z",
     "iopub.status.idle": "2021-08-15T06:24:08.812644Z",
     "shell.execute_reply": "2021-08-15T06:24:08.811482Z",
     "shell.execute_reply.started": "2021-08-15T06:24:07.127097Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.01833662, ..., 0.        , 0.13808796,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.3209723 , 0.23934594,\n",
       "        0.10782446],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.11698917, 0.        , ..., 0.18727249, 0.2615693 ,\n",
       "        0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "#saving the word representations output by the model (which was trained on the primary task) and using it to test the probe's performance\n",
    "\n",
    "# with a Sequential model\n",
    "get_3rd_layer_output = K.function([probe_model.layers[0].input],\n",
    "                                  [probe_model.layers[3].output])\n",
    "x_test_representation = get_3rd_layer_output(task_test_1)[0]\n",
    "x_test_representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-15T06:24:08.814434Z",
     "iopub.status.busy": "2021-08-15T06:24:08.814054Z",
     "iopub.status.idle": "2021-08-15T06:24:08.818513Z",
     "shell.execute_reply": "2021-08-15T06:24:08.817518Z",
     "shell.execute_reply.started": "2021-08-15T06:24:08.814402Z"
    }
   },
   "outputs": [],
   "source": [
    "x_test_representation = x_test_representation.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-15T06:24:08.820111Z",
     "iopub.status.busy": "2021-08-15T06:24:08.819643Z",
     "iopub.status.idle": "2021-08-15T06:24:08.832369Z",
     "shell.execute_reply": "2021-08-15T06:24:08.831483Z",
     "shell.execute_reply.started": "2021-08-15T06:24:08.820069Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1500000,)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_representation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-15T06:24:08.834301Z",
     "iopub.status.busy": "2021-08-15T06:24:08.833753Z",
     "iopub.status.idle": "2021-08-15T06:24:12.227628Z",
     "shell.execute_reply": "2021-08-15T06:24:12.226679Z",
     "shell.execute_reply.started": "2021-08-15T06:24:08.834227Z"
    }
   },
   "outputs": [],
   "source": [
    "#saving the output of the model\n",
    "df_test_1 = pd.DataFrame(x_test_representation, columns = ['test_sentences'])\n",
    "\n",
    "df_test_1.to_csv('x_test.csv', index = False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
